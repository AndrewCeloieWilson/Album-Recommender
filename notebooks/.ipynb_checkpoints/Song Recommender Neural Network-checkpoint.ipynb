{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8232102e-b989-49e9-a07f-bc67a4b8ae41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Before proceeding please update the HEADERS value in config.py to include your e-mail address\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from src.extract_training_data import extract_and_save_raw_audio_features\n",
    "from src.train_model import train_model\n",
    "from src.output_trained_model_data import output_model_data\n",
    "from src.predict_with_model import search_for_album_you_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b5b5c-a3da-4cee-b783-181377254c59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === STEP 1: Data Extraction ===\n",
    "# This function reads your 'my_liked_and_disliked_tracks.csv' from the raw data folder\n",
    "# For each track, it fetches detailed audio features from AcousticBrainz and metadata from MusicBrainz\n",
    "# and saves an enriched CSV file including all features.\n",
    "# This CSV will be the base dataset for training.\n",
    "extract_and_save_raw_audio_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55500599-04e0-4c50-88c7-0550863482c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2: Model Training ===\n",
    "# These hyperparameters control your neural network training process.\n",
    "# Feel free to tune them to improve model performance or training speed.\n",
    "TEST_SIZE = 0.1                     # 10% of data reserved for testing the model\n",
    "NUMBER_OF_EPOCHS = 2000             # Number of full passes over the training dataset\n",
    "BATCH_SIZE = 32                     # Number of samples per training update (mini-batch)\n",
    "LEARNING_RATE = 0.00001             # Step size for optimizer updates, smaller = slower but more precise\n",
    "ADAMS_OPTIMIZER_WEIGHT_DECAY = 0.0001  # L2 regularization strength to avoid overfitting\n",
    "EVALUATE_EVERY_X_EPOCHS = 1        # How often to evaluate and print training progress\n",
    "TARGET_TEST_ACCURACY = 0.85         # Early stopping threshold: if test accuracy reaches this, stop training\n",
    "\n",
    "# Train the model on the extracted and transformed dataset.\n",
    "# This function performs:\n",
    "# - Loading and cleaning the raw feature CSV\n",
    "# - Scaling numeric features with MinMaxScaler\n",
    "# - Encoding categorical variables (like musical key and scale)\n",
    "# - Splitting into train and test sets\n",
    "# - Initializing the neural network architecture (from src.model.Net)\n",
    "# - Training the model using binary cross-entropy loss and Adam optimizer\n",
    "# - Periodic evaluation on train and test sets, printing progress\n",
    "# - Early stopping if test accuracy threshold is hit\n",
    "train_model(\n",
    "    test_size=TEST_SIZE, \n",
    "    num_epochs=NUMBER_OF_EPOCHS,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    learning_rate=LEARNING_RATE, \n",
    "    adams_optimizer_weight_decay=ADAMS_OPTIMIZER_WEIGHT_DECAY,\n",
    "    evaluate_every_x_epochs=EVALUATE_EVERY_X_EPOCHS,\n",
    "    target_test_accuracy=TARGET_TEST_ACCURACY  # <-- important to enable early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b0e7b-d196-46da-8bf9-dc505c2276e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3: Output Model Data ===\n",
    "# This function generates output based on the trained model:\n",
    "# - May produce evaluation reports like final accuracy, loss curves\n",
    "# - Could save model summary statistics or metadata for future analysis\n",
    "# - Prepares information needed for downstream tasks such as recommendation\n",
    "output_model_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fc1a6-725e-411d-a0c7-fefabab085a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 4: Album Recommendation Search ===\n",
    "# These thresholds guide your album recommendation logic:\n",
    "LIKED_SONG_THRESHOLD = 0.9           # Minimum predicted probability for a song to be considered \"liked\"\n",
    "ALBUM_RECOMMENDATION_THRESHOLD = 0.8  # Minimum average \"liked\" probability across album tracks to recommend\n",
    "ALBUM_TRACK_LENGTH_THRESHOLD = 5     # Minimum number of tracks in an album for it to qualify for recommendation\n",
    "\n",
    "# This function searches through your dataset or external sources for albums matching your criteria:\n",
    "# - It scores each song using the trained model's predictions\n",
    "# - Aggregates scores by album\n",
    "# - Filters albums by track count and average liked prediction score\n",
    "# - Outputs or prints albums you are likely to enjoy based on learned preferences\n",
    "search_for_album_you_like(\n",
    "    LIKED_SONG_THRESHOLD, \n",
    "    ALBUM_RECOMMENDATION_THRESHOLD,\n",
    "    ALBUM_TRACK_LENGTH_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32bf96-5ebf-4336-b4de-84c9475f0ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
