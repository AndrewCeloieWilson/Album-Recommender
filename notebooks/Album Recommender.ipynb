{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232102e-b989-49e9-a07f-bc67a4b8ae41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Before proceeding please update the HEADERS value in config.py to include your e-mail address\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from src.extract_training_data import extract_and_save_raw_audio_features\n",
    "from src.train_model import train_model\n",
    "from src.output_trained_model_data import output_model_data\n",
    "from src.predict_with_model import search_for_album_you_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b5b5c-a3da-4cee-b783-181377254c59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === STEP 1: Data Extraction ===\n",
    "# This function reads your 'my_liked_and_disliked_tracks.csv' from the raw data folder and gathers associated audio features from \n",
    "# Acoustic Brainz and Music Brainz.\n",
    "#\n",
    "# A set of 1500 liked and disliked songs has already been included, as well as the raw data this method extracts. This can be used without modification.\n",
    "# If you want to train the neural network using that data, you can skip directly to the training step.\n",
    "#\n",
    "# If you want to use your own data, you need to update the 'my_liked_and_disliked_tracks.csv' file in data/raw.\n",
    "# Your 'my_liked_and_disliked_tracks.csv' file needs to contain a column of 'mbid' IDs representing the unique music brainz ID of \n",
    "# songs you like. A second column 'liked' should include a 1 or 0 representing if you like or dislike the given song.\n",
    "# Ideally, include about 50% liked and 50% disliked songs.\n",
    "#\n",
    "# For each track, this function fetches detailed audio features from AcousticBrainz and metadata from MusicBrainz\n",
    "# and saves an enriched CSV file including all features. This CSV will be saved in data/raw and will be the base dataset for training.\n",
    "extract_and_save_raw_audio_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55500599-04e0-4c50-88c7-0550863482c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2: Model Training ===\n",
    "# These hyperparameters control your neural network training process.\n",
    "# Feel free to tune them to improve model performance or training speed.\n",
    "TEST_SIZE = 0.1                        # Percentage of data reserved for testing the model\n",
    "NUMBER_OF_EPOCHS = 1000                # Number of full passes over the training dataset\n",
    "BATCH_SIZE = 32                        # Number of samples per training update (mini-batch)\n",
    "LEARNING_RATE = 0.0001                 # Step size for optimizer updates, smaller = slower but more precise\n",
    "ADAMS_OPTIMIZER_WEIGHT_DECAY = 0.0001  # Regularization strength to avoid overfitting\n",
    "EVALUATE_EVERY_X_EPOCHS = 1            # How often to evaluate and print training progress, as well as check for the \n",
    "                                       # early stopping threshold set by TARGET_TEST_ACCURACY.\n",
    "TARGET_TEST_ACCURACY = 0.85            # Early stopping threshold: If test accuracy reaches this percentage, stop training and save the model.\n",
    "\n",
    "# Train the model on the extracted and transformed dataset, as well as the model set up in src/model.py.\n",
    "# If desired you can update the model structure in src/model.py to try out different numbers of layers, different activation functions, etc. \n",
    "# This function performs:\n",
    "# Loading and cleaning the raw feature CSV\n",
    "# Scaling numeric features with MinMaxScaler and saving the scaler object to scaler.joblib\n",
    "# Encoding categorical variables (like musical key and scale)\n",
    "# Splitting into train and test sets\n",
    "# Initializing the neural network architecture (from src.model.Net in src/model.py)\n",
    "# Training the model using binary cross-entropy loss and Adam optimizer\n",
    "# Periodic evaluation on train and test sets, and printing progress of average loss.\n",
    "# The average loss represents the target liked/disliked value (1 or 0) minus the predicted value averaged over the epoch. \n",
    "# Early stopping if test accuracy threshold is hit\n",
    "# Saves the trained model to song_pref_model_weights.pth in the output/models folder\n",
    "train_model(\n",
    "    test_size=TEST_SIZE, \n",
    "    num_epochs=NUMBER_OF_EPOCHS,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    learning_rate=LEARNING_RATE, \n",
    "    adams_optimizer_weight_decay=ADAMS_OPTIMIZER_WEIGHT_DECAY,\n",
    "    evaluate_every_x_epochs=EVALUATE_EVERY_X_EPOCHS,\n",
    "    #target_test_accuracy=TARGET_TEST_ACCURACY  # <-- important to enable early stopping once an ideal stopping point has been identified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b0e7b-d196-46da-8bf9-dc505c2276e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3: Output Model Data ===\n",
    "# This function generates output based on the trained model and saves it in the data/output/weights folder\n",
    "# Produces csv files that give information on bias, grouped importance of features, top 10 features, and weights per layer\n",
    "# of the neural network\n",
    "# These can be used to glean information about what the neural network learned from the dataset, how it is making recommendations,\n",
    "# and why it has overfit or underfit the dataset.\n",
    "output_model_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fc1a6-725e-411d-a0c7-fefabab085a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 4: Album Recommendation Search ===\n",
    "# These thresholds guide your album recommendation logic:\n",
    "LIKED_SONG_THRESHOLD = 0.5            # Minimum predicted probability for a song to be considered \"liked\"\n",
    "ALBUM_RECOMMENDATION_THRESHOLD = 0.5  # Minimum percentage of \"liked\" album tracks needed to recommend the album\n",
    "ALBUM_TRACK_LENGTH_THRESHOLD = 5      # Minimum number of tracks in an album for it to qualify for recommendation\n",
    "\n",
    "# This function searches through MusicBrainz for albums matching your criteria:\n",
    "# It scores each song using the trained model's weights to make a prediction.\n",
    "# It determines if the album has enough total songs and enough liked songs to recommend\n",
    "# Outputs or prints albums you are likely to enjoy based on learned preferences\n",
    "# Please note that this is slow due to Music Brainz and Acoustic Brainz being Free APIs\n",
    "# Which allow one query per second, and due to a high number of Music Brainz albums not having\n",
    "# The necessary low level features that the neural network has been trained on\n",
    "#\n",
    "# IMPORTANT: Before proceeding please update the HEADERS value in config.py to include your e-mail address\n",
    "#\n",
    "search_for_album_you_like(\n",
    "    LIKED_SONG_THRESHOLD, \n",
    "    ALBUM_RECOMMENDATION_THRESHOLD,\n",
    "    ALBUM_TRACK_LENGTH_THRESHOLD\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
